{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"right\"><i>COM418 - Computers and Music</i></div>\n",
    "<div align=\"right\"><a href=\"https://people.epfl.ch/paolo.prandoni\">Lucie Perrotta</a>, <a href=\"https://www.epfl.ch/labs/lcav/\">LCAV, EPFL</a></div>\n",
    "\n",
    "<p style=\"font-size: 30pt; font-weight: bold; color: #B51F1F;\">Channel Vocoder</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Audio\n",
    "from IPython.display import IFrame\n",
    "from scipy import signal\n",
    "\n",
    "import import_ipynb\n",
    "from Helpers import * \n",
    "\n",
    "figsize=(10,5)\n",
    "import matplotlib\n",
    "matplotlib.rcParams.update({'font.size': 16});"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs=44100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will implement and test an easy **channel vocoder**. A channel vocoder is a musical device that allows to sing while playing notes on a keyboard at the same time. The vocoder blends the voice (called the modulator) with the played notes on the keyboard (called the carrier) so that the resulting voice sings the note played on the keyboard. The resulting voice has a robotic, artificial sound that is rather popular in electronic music, with notable uses by bands such as Daft Punk, or Kraftwerk.\n",
    "\n",
    "<img src=\"https://www.bhphotovideo.com/images/images2000x2000/waldorf_stvc_string_synthesizer_1382081.jpg\" alt=\"Drawing\" style=\"width: 35%;\"/>\n",
    "\n",
    "The implementation of a Channel vocoder is in fact quite simple. It takes 2 inputs, the carrier and the modulator signals, that must be of the same length. It divides each signal into frequency bands called **channels** (hence the name) using many parallel bandpass filters. The width of each channel can be equal, or logarithmically sized to match the human ear perception of frequency. For each channel, the envelope of the modulator signal is then computed, for instance using a rectifier and a moving average. It is simply multiplied to the carrier signal for each channel, before all channels are added back together.\n",
    "\n",
    "<img src=\"https://i.imgur.com/aIePutp.png\" alt=\"Drawing\" style=\"width: 65%;\"/>\n",
    "\n",
    "To improve the intelligibility of the speech, it is also possible to add AWGN to each to the carrier of each band, helping to produce non-voiced sounds, such as the sound s, or f. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an example signal to test our vocoder with, we are going to use dry voice samples from the song \"Nightcall\" by french artist Kavinsky.\n",
    "\n",
    "![Nightcall](https://upload.wikimedia.org/wikipedia/en/5/5b/Kavinsky_Nightcall_2010.png)\n",
    "\n",
    "First, let's listen to the original song: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IFrame(src=\"https://www.youtube.com/embed/46qo_V1zcOM?start=30\", width=\"560\", height=\"315\", frameborder=\"0\", allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. The modulator and the carrier signals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "We are now going to recreate the lead vocoder using 2 signals: we need a modulator signal, a voice pronouning the lyrics, and a carrier signal, a synthesizer, containing the notes for the pitch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. The modulator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first import the modulator signal. It is simply the lyrics spoken at the right rhythm. No need to sing or pay attention to the pitch, only the prononciation and the rhythm of the text are going to matter. Note that the voice sample is available for free on **Splice**, an online resource for audio production."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nightcall_modulator = open_audio('snd/nightcall_modulator.wav')\n",
    "Audio('snd/nightcall_modulator.wav', autoplay=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. The carrier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second, we import a carrier signal, which is simply a synthesizer playing the chords that are gonna be used for the vocoder. Note that the carrier signal does not need to feature silent parts, since the modulator's silences will automatically mute the final vocoded track. The carrier and the modulator simply need to be in synch with each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nightcall_carrier = open_audio('snd/nightcall_carrier.wav')\n",
    "Audio(\"snd/nightcall_carrier.wav\", autoplay=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. The channel vocoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. The channeler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now start implementing the phase vocoder. The first tool we need is an efficient filter to allow decomposing both the carrier and the modulator signals into channels (or bands). Let's call this function the **channeler** since it decomposes the input signals into frequency channels. It takes as input a signal to be filtered, a integer representing the number of bands, and a boolean for setting if we want white noise to be added to each band (used for the carrier)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def channeler(x, n_bands, add_noise=False):\n",
    "    \"\"\"\n",
    "    Separate a signal into log-sized frequency channels.\n",
    "    x: the input signal\n",
    "    n_bands: the number of frequency channels\n",
    "    add_noise: add white noise or note to each channel\n",
    "    \"\"\"\n",
    "    band_freqs = np.logspace(2, 14, n_bands+1, base=2) # get all the limits between the bands, in log space\n",
    "    \n",
    "    x_bands = np.zeros((n_bands, x.size)) # Placeholder for all bands\n",
    "    \n",
    "    for i in range(n_bands):\n",
    "        noise = 0.7*np.random.random(x.size) if add_noise else 0 # Create AWGN or not\n",
    "        x_bands[i] = butter_pass_filter(x + noise, np.array((band_freqs[i], band_freqs[i+1])), fs, btype=\"band\", order=5).astype(np.float32) # Carrier + uniform noise \n",
    "\n",
    "    return x_bands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example plot\n",
    "plt.figure(figsize=figsize)\n",
    "plt.magnitude_spectrum(nightcall_carrier)\n",
    "plt.title(\"Carrier signal before channeling\")\n",
    "plt.xscale(\"log\")\n",
    "plt.xlim(1e-4)\n",
    "plt.show()\n",
    "\n",
    "carrier_bands = channeler(nightcall_carrier, 8, add_noise=True)\n",
    "plt.figure(figsize=figsize)\n",
    "for i in range(8):\n",
    "    plt.magnitude_spectrum(carrier_bands[i], alpha=.7)\n",
    "plt.title(\"Carrier channels after channeling and noise addition\")\n",
    "plt.xscale(\"log\")\n",
    "plt.xlim(1e-4)\n",
    "plt.show()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. The envelope computer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we can implement a simple envelope computer. Given a signal, this function computes its temporal envelope."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def envelope_computer(x):\n",
    "    \"\"\"\n",
    "    Envelope computation of one channels of the modulator\n",
    "    x: the input signal\n",
    "    \"\"\"\n",
    "    x = np.abs(x) # Rectify the signal to positive\n",
    "    x = moving_average(x, 1000) # Smooth the signal\n",
    "    return 3*x # Normalize # Normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=figsize)\n",
    "plt.plot(np.abs(nightcall_modulator)[:150000] , label=\"Modulator\")\n",
    "plt.plot(envelope_computer(nightcall_modulator)[:150000], label=\"Modulator envelope\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.title(\"Modulator signal and its envelope\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. The channel vocoder (itself)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now implement the channel vocoder itself! It takes as input both signals presented above, as well as an integer controlling the number of channels (bands) of the vocoder. A larger number of channels results in the finer grained vocoded sound, but also takes more time to compute. Some artists may voluntarily use a lower numer of bands to increase the artificial effect of the vocoder. Try playing with it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def channel_vocoder(modulator, carrier, n_bands=32):\n",
    "    \"\"\"\n",
    "    Channel vocoder\n",
    "    modulator: the modulator signal\n",
    "    carrier: the carrier signal\n",
    "    n_bands: the number of bands of the vocoder (better to be a power of 2)\n",
    "    \"\"\"\n",
    "    # Decompose both modulation and carrier signals into frequency channels\n",
    "    modul_bands = channeler(modulator, n_bands, add_noise=False)\n",
    "    carrier_bands = channeler(carrier, n_bands, add_noise=True)\n",
    "    \n",
    "    # Compute envelope of the modulator\n",
    "    modul_bands = np.array([envelope_computer(modul_bands[i]) for i in range(n_bands)])\n",
    "\n",
    "    # Multiply carrier and modulator\n",
    "    result_bands = np.prod([modul_bands, carrier_bands], axis=0)\n",
    "\n",
    "    # Merge back all channels together and normalize\n",
    "    result = np.sum(result_bands, axis=0)\n",
    "    return normalize(result) # Normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nightcall_vocoder = channel_vocoder(nightcall_modulator, nightcall_carrier, n_bands=32)\n",
    "Audio(nightcall_vocoder, rate=fs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The vocoded voice is still perfectly intelligible, and it's easy to understand the lyrics. However, the pitch of the voice is now the synthesizer playing chords! One can try to deactivate the AWGN and compare the results. We finally plot the STFT of all 3 signals. One can notice that the vocoded signal has kept the general shape of the voice (modulator) signal, but is using the frequency information from the carrier!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "f, t, Zxx = signal.stft(nightcall_modulator[:7*fs], fs, nperseg=1000)\n",
    "plt.figure(figsize=figsize)\n",
    "plt.pcolormesh(t, f[:100], np.abs(Zxx[:100,:]), cmap='nipy_spectral', shading='gouraud')\n",
    "plt.title(\"Original voice (modulator)\")\n",
    "plt.ylabel('Frequency [Hz]')\n",
    "plt.xlabel('Time [sec]')\n",
    "plt.show()\n",
    "\n",
    "f, t, Zxx = signal.stft(nightcall_vocoder[:7*fs], fs, nperseg=1000)\n",
    "plt.figure(figsize=figsize)\n",
    "plt.pcolormesh(t, f[:100], np.abs(Zxx[:100,:]), cmap='nipy_spectral', shading='gouraud')\n",
    "plt.title(\"Vocoded voice\")\n",
    "plt.ylabel('Frequency [Hz]')\n",
    "plt.xlabel('Time [sec]')\n",
    "plt.show()\n",
    "\n",
    "f, t, Zxx = signal.stft(nightcall_carrier[:7*fs], fs, nperseg=1000)\n",
    "plt.figure(figsize=figsize)\n",
    "plt.pcolormesh(t, f[:100], np.abs(Zxx[:100,:]), cmap='nipy_spectral', shading='gouraud')\n",
    "plt.title(\"Carrier\")\n",
    "plt.ylabel('Frequency [Hz]')\n",
    "plt.xlabel('Time [sec]')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Playing it together with the music"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's try to play it with the background music to see if it sounds like the original!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nightcall_instru = open_audio('snd/nightcall_instrumental.wav')\n",
    "\n",
    "nightcall_final = nightcall_vocoder + 0.6*nightcall_instru\n",
    "nightcall_final = normalize(nightcall_final) # Normalize\n",
    "\n",
    "Audio(nightcall_final, rate=fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
