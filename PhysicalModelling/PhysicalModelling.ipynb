{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb5efe33-1db3-4122-b05e-21069dd704c6",
   "metadata": {},
   "source": [
    "<div align=\"right\"><i>COM418 - Computers and Music</i></div>\n",
    "<div align=\"right\"><a href=\"https://people.epfl.ch/paolo.prandoni\">Lucie Perrotta</a>, <a href=\"https://www.epfl.ch/labs/lcav/\">LCAV, EPFL</a></div>\n",
    "\n",
    "<p style=\"font-size: 30pt; font-weight: bold; color: #B51F1F;\">Physical Modelling</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f56f66-cfb1-4237-a5ae-be51b7ab62d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import ipywidgets as widgets\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Audio\n",
    "from scipy import signal\n",
    "\n",
    "import import_ipynb\n",
    "from Helpers import * \n",
    "\n",
    "import matplotlib\n",
    "figsize=(10,5)\n",
    "matplotlib.rcParams.update({'font.size': 16});"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76754882-f912-489a-afd5-7e8b0bcc42a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fs=44100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "915cb56c-781e-4aa7-9ca0-6d178d395d94",
   "metadata": {},
   "source": [
    "## 1. Karplusâ€“Strong string synthesis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae34d31c-7f32-43f9-892f-7078f8e2b905",
   "metadata": {},
   "source": [
    "A rather easy model for synthesizing a string was proposed in 1983 in the article \"Digital Synthesis of Plucked String and Drum Timbres\" by Karplus and Strong. It defines the string as being a very short noise generator followed by a lowpass loop. The delay of the loop determines the frequency of the string, and the length of the noise burst the \"precision\" of the picking of the string. Hence, a short noise burst would generate a rather \"striked string\" sound, corresponding to instruments such as the harpsicord, while longer noise burst would create a more \"bowed string\" sound, such as a violin.\n",
    "\n",
    "The diagram is as follows\n",
    "\n",
    "<img src=\"pictures/strong.png\" alt=\"Drawing\" style=\"width: 60%;\"/>\n",
    "\n",
    "where the lowpass filter is typically implement using a simple moving average over the past samples. The size of the moving average influences the dampening of the string over time.\n",
    "\n",
    "The value $N$ (in samples) of the delay is simply calculated by (euclidean) dividing the sampling frequency $f_s$ by the desired string frequency $f$,\n",
    "$$\n",
    "N = \\lfloor fs /f \\rfloor .\n",
    "$$\n",
    "\n",
    "Let's implement it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64076d28-dd5c-440c-b5ea-cb0117c66283",
   "metadata": {},
   "outputs": [],
   "source": [
    "def karplus_strong(freq, pinch=.02, sustain=.99, dampen=2, duration=2, lowpass=False):\n",
    "    \"\"\"\n",
    "    Plays a string sound using the Karplus-Strong model.\n",
    "    freq: the frequency (in hertz) of the played string\n",
    "    pinch: the length (in seconds) of the initial pinching of the string\n",
    "    sustain: the sustain factor of the vibration of the string after the pinching (1 is normal sustain)\n",
    "    dampen: the level of dampening of the string (1 = no dampen, higher int values is more dampen)\n",
    "    duration: the duration of the output sound in seconds\n",
    "    lowpass: apply a lowpass to the output signal\n",
    "    returns: a numpy array containing the vibrating string's data\n",
    "    \"\"\"\n",
    "    out = np.zeros(int(duration*fs)) # placeholder for the output\n",
    "    burst = 2*np.random.random(int(pinch*fs)) - 1 # Random noise in [-1, 1] lasting pinch ms\n",
    "    out[:int(pinch*fs)] = burst # output starts with burst\n",
    "    \n",
    "    delay = int(fs//freq) # delay of the loop (in samples)\n",
    "    for i in range(delay, int(duration*fs)): # delay loop\n",
    "        out[i] += sustain * np.mean(out[i-delay:i-delay+dampen])\n",
    "        \n",
    "    if lowpass: out = butter_pass_filter(out, np.array([int(10*freq)]), fs, \"low\", order=1)\n",
    "    return normalize(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef2a333d-1e37-4067-89bb-8b842ee89b4e",
   "metadata": {},
   "source": [
    "Let's test it with a 200Hz frequency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18ffb9c9-de5b-43ba-b16d-ee0623695096",
   "metadata": {},
   "outputs": [],
   "source": [
    "string = karplus_strong(150, lowpass=True)\n",
    "\n",
    "Audio(string, rate=fs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad8a9172-824b-45a1-9eea-1b047d35c503",
   "metadata": {},
   "source": [
    "Sounds quite synthetic, but given the simplycity of the code above, this is already quite good! Let's have a look at the frequencies and try playing with them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb003dc-6624-4168-b0f7-f0faa9f73ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "@widgets.interact(freq=(50, 500, 50), pinch=(0.1, 0.5, 0.1), sustain=(.98, 1, 0.001), damper=(1, 10, 1))\n",
    "def update(freq=200, pinch=.02, sustain=.99, damper=2,):\n",
    "    \n",
    "    test = karplus_strong(freq, pinch, sustain, damper, duration=2)\n",
    "\n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.plot(test)\n",
    "    plt.xlabel(\"Time [samples]\")\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.magnitude_spectrum(test)\n",
    "    plt.xlim(0, .3)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb4e419b-1172-4461-a434-ea83a95f4bb5",
   "metadata": {},
   "source": [
    "The frequency spectrum is quite rich already. Try playing with the sliders and observe how each parameter influences the spectrum.\n",
    "\n",
    "### 1.1. Play a song!\n",
    "\n",
    "We can now test our guitar with the Pacman melody from the 1-bit music notebook. To this extent, we simply need to convert it to a function that can be pass to the melody player from this notebook, i.e. a function taking only an angular frequency $\\omega$ and a length $N$ in samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a07f1025-4dc2-4a62-82b0-ba9b56251c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def guitar(w,N):\n",
    "    return karplus_strong(w*fs/2/np.pi, pinch=.02, sustain=.995, dampen=2, duration=N/fs, lowpass=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1daa5a1a-22c8-42d6-89f4-d4df7f8606af",
   "metadata": {},
   "source": [
    "Play it, Jonnie!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f95671d9-6a7a-4785-89dc-936280d39980",
   "metadata": {},
   "outputs": [],
   "source": [
    "tune = (('B4', 2), ('B5', 2), ('F#5', 2), ('D#5', 2), ('B5', 1), ('F#5', 3), ('D#5', 4), \n",
    "        ('C5', 2), ('C6', 2), ('G5', 2),  ('E5', 2),  ('C6', 1), ('G5', 3),  ('E5', 4),\n",
    "        ('B4', 2), ('B5', 2), ('F#5', 2), ('D#5', 2), ('B5', 1), ('F#5', 3), ('D#5', 4), \n",
    "        ('D#5', 1), ('E5', 1), ('F5', 2), ('F5', 1), ('F#5', 1), ('G5', 2), ('G5', 1), \n",
    "        ('G#5', 1), ('A5', 2), ('B5', 4))\n",
    "\n",
    "jingle = play_notes(tune, time_scale=0.02, rate=4*fs, wave_engine=guitar)\n",
    "Audio(jingle, rate=fs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d520dd1-b577-43f1-8e46-4fce14bbc23f",
   "metadata": {},
   "source": [
    "## 2. Drums"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ea01c77-e9d5-4140-9b08-9bf1e6a6264e",
   "metadata": {},
   "source": [
    "### 2.1. Kick"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dd862f5-a4aa-4d5e-a755-4a60fb1ae80b",
   "metadata": {},
   "source": [
    "Physically, a kick (a bass drum) is a large drum, around 20 inches in diameter, one side of it, the beat drum head, being hit with a hammer generally attached to a pedal, or hold in hand. The other side is covered with another drum head for resonance. The tension of the drum heads can be controlled with screws, and is tuned to optimally resonate with the geometry of the drum. When the hit by the hammer, t A simple way to model a kick is to generate a sine sweep that starts at a high pitch, around 14kHz, and then quickly goes down to a lower pitch at 20Hz and stays there for 200ms. Simply multiply this by the envelope described above and you obtain a very recognizable electronic kick sound. One can model toms and other kinds of simple drum in a similar fashion by using different start and end frequencies for the sweep. Similarly, the resonance of the drum can be tuned by the length of the sweep and the envelope. For instance, the 1980s saw a prominence in the popularity of headless drums, bass drums without a resonance drum head, generating shorter, more precise kicks.he tension in the drum head increase briefly generating a very short (around 20ms) high pitch noise. This initial \"burst\" contributes to the attack (the \"kick\") of the bass drum sound. As the beating ends, the vibration of the drum head continues with a lower tension, resulting in a lower pitch that immediately follows the first \"burst\", and fades away after 200ms.\n",
    "\n",
    "<img src=\"https://d1aeri3ty3izns.cloudfront.net/media/49/499096/1200/preview.jpg\" alt=\"Drawing\" style=\"width: 30%;\"/>\n",
    "\n",
    "A simple way to model a kick is to generate a sine sweep that starts at a high pitch, around 14kHz, and then quickly goes down to a lower pitch at 20Hz and stays there for 200ms. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d83d4b5a-9d5d-4623-88e1-2ecd51ac5a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = np.linspace(0, 1/4, int(fs/4))\n",
    "sweep = signal.chirp(t, f0=14000, t1=.25, f1=20, method=\"hyperbolic\")\n",
    "\n",
    "# Plot\n",
    "f, t, Zxx = signal.stft(sweep, fs, nperseg=400)\n",
    "plt.figure(figsize=figsize)\n",
    "plt.pcolormesh(t, f, np.abs(Zxx), cmap='nipy_spectral', shading='gouraud')\n",
    "plt.ylabel('Frequency [Hz]')\n",
    "plt.xlabel('Time [sec]')\n",
    "plt.ylim(20, 14000)\n",
    "plt.yscale(\"log\")\n",
    "#plt.savefig(\"kick_stft.pdf\", dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ae23989-e3d1-488d-8492-80731e2d254e",
   "metadata": {},
   "source": [
    "Amplitude-wise, a kick as a fast attack, going from 0 to 1 during the initial burst phase. Then, as soon as the resonance phase starts, the amplitude decreases logarithmically back to 0 until 200ms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d35d6eb-6b0b-4b3d-a804-b105b027f641",
   "metadata": {},
   "outputs": [],
   "source": [
    "envelope = np.ones(sweep.size) \n",
    "envelope[:10] = np.linspace(0,1,10)\n",
    "envelope[10:] = np.logspace(0, -2, envelope.size-10)\n",
    "\n",
    "plt.figure(figsize=figsize)\n",
    "plt.plot(envelope)\n",
    "plt.xlabel(\"Time [samples]\")\n",
    "plt.ylabel(\"Envelope amplitude\")\n",
    "#plt.savefig(\"kick_env.pdf\", dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59c3b03e-d41e-4e07-9f88-b8bad719d901",
   "metadata": {},
   "source": [
    "Simply multiply this by the envelope described above and you obtain a very recognizable electronic kick sound. One can model toms and other kinds of simple drum in a similar fashion by using different start and end frequencies for the sweep. Similarly, the resonance of the drum can be tuned by the length of the sweep and the envelope. For instance, the 1980s saw a prominence in the popularity of headless drums, bass drums without a resonance drum head, generating shorter, more precise kicks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f8d0f0c-bf29-4233-9953-468c0d3222af",
   "metadata": {},
   "outputs": [],
   "source": [
    "kick = normalize(sweep * envelope)\n",
    "\n",
    "plt.figure(figsize=figsize)\n",
    "plt.plot(kick)\n",
    "plt.xlabel(\"Time [samples]\")\n",
    "plt.ylabel(\"Amplitude\")\n",
    "#plt.savefig(\"kick.pdf\", dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "Audio(kick, rate=fs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94091c2f-13e7-44ba-b6e7-93b48f454a81",
   "metadata": {},
   "source": [
    "There we go! An amazing tekno-hardcore sounding kick! A couple more steps and we're ready for the rave."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab23a1fb-c896-4f16-908c-ebf115966289",
   "metadata": {},
   "source": [
    "### 2.2. Snare"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b79f20c-f619-4538-bad3-790319f6f6a8",
   "metadata": {},
   "source": [
    "A snare drum is a drum with the particularity if being flatter than other drums (typically 7 inches), and to feature drums (hence the name) on the resonance drum head. Both drum heads of the snare are generally stretched with a higher tension than the other drums. The flatness of the snare generate a very sharp, short tom-like sound, while the drums add to the snare sound its signature noise sound.\n",
    "\n",
    "<img src=\"https://www.collinsdictionary.com/images/full/snaredrum_233695612_1000.jpg\" alt=\"Drawing\" style=\"width: 30%;\"/>\n",
    "\n",
    "To model a simple snare, we will use 2 components: a noise sound modelling the snares, and a sine wave modelling the resonance of the snare drum's body. The noise is a filtered white noise with frequencies concentrated between 100 and 2000Hz. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "224bd5d2-4a61-4a15-91ba-2d2e7e2df549",
   "metadata": {},
   "outputs": [],
   "source": [
    "length = int(fs/4)\n",
    "\n",
    "noise = 2*np.random.random(length) - 1\n",
    "noise = butter_pass_filter(noise, np.array([10, 2000]), fs, \"band\", order=1)\n",
    "\n",
    "Audio(noise, rate=fs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3410904a-c883-40c8-b879-7c660a382cdd",
   "metadata": {},
   "source": [
    "The sine is a simple 100Hz wave with length 1/4 seconds. Note that for a snare drum, the drum heads are sufficiently tight so that we do not observe the logarithmic swipe effect as in the bass drum, hence a simple sine is enough. Let us import our sine wave generator from the Synthesizer notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "976c5157-7a63-4419-aeb4-06c3efcb7123",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sine(A, w, phi, n):\n",
    "    return A * np.sin(w*n - phi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598160a4-371b-41ba-acd9-fe2d94974abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_sine = sine(1, 100/fs*2*np.pi, 0, np.arange(length))\n",
    "Audio(my_sine, rate=fs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05f26bf7-d5b7-495c-aa12-4f6d3095a531",
   "metadata": {},
   "source": [
    "Both the noise and the sine are then passed through a respective envelope, with a shape similar to the bass drum's. The envelope of the noise ends shorter than the envelope of the sine, as the snares stop vibrating before the heads themselves. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f23272-c7aa-4673-a1be-d97d751bd587",
   "metadata": {},
   "outputs": [],
   "source": [
    "envelope_n = np.ones(length) \n",
    "envelope_n[:10] = np.linspace(0,1,10)\n",
    "envelope_n[10:] = np.logspace(0, -3, envelope_n.size-10)\n",
    "\n",
    "envelope = np.ones(length) \n",
    "envelope[:10] = np.linspace(0,1,10)\n",
    "envelope[10:] = np.logspace(0, -2, envelope.size-10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9e16b7b-5ed1-40a9-8f93-ef531859fae0",
   "metadata": {},
   "source": [
    "We finally simply add the noise with the sine, with more noise than sine. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e42f6f7-d7e0-4b23-a123-b1026a3d2e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "snare = normalize( 0.8*envelope_n*noise + 0.2*envelope*my_sine )\n",
    "\n",
    "plt.figure(figsize=figsize)\n",
    "plt.plot(snare)\n",
    "plt.xlabel(\"Time [samples]\")\n",
    "plt.ylabel(\"Amplitude\")\n",
    "#plt.savefig(\"snare.pdf\", dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Plot\n",
    "f, t, Zxx = signal.stft(snare, fs, nperseg=400)\n",
    "plt.figure(figsize=figsize)\n",
    "plt.pcolormesh(t, f, np.abs(Zxx), cmap='nipy_spectral', shading='gouraud')\n",
    "plt.ylabel('Frequency [Hz]')\n",
    "plt.xlabel('Time [sec]')\n",
    "plt.ylim(20, 22500)\n",
    "plt.yscale(\"log\")\n",
    "#plt.savefig(\"snare_stft.pdf\", dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "Audio(snare, rate=fs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e454db64-0df1-4b32-9f33-e71174173830",
   "metadata": {},
   "source": [
    "### 2.3. Hats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be489ef2-75f8-47c0-82ad-4fae8255e8a2",
   "metadata": {},
   "source": [
    "Cymbals are worked plates of bronze whose usage is very versatile in a drumset. Some cymbals are used to lead the rhythm of the music, while some are used to highlight accents on some particular beats. Among the cymbals, the hi-hat is probably the most important one. It consists in 2 cymbals facing each other, mounted on a stand that allows to control the distance between the cymbals using a pedal. If the distance is large, the hi-hat is said to be open and the cymbals can resonate. If the distance is small, i.e. the cymbals touch each other, the hi-hat is said to be closed and the sound is more precise and muffled.\n",
    "\n",
    "<img src=\"https://static.keymusic.com/products/240938/XL/sabian-xsr-rock-hihat-14.jpg\" alt=\"Drawing\" style=\"width: 30%;\"/>\n",
    "\n",
    "Modelling cymbals can actually be done fairly easily. One can simply generate a white noise and filter it to only keep the high frequencies. The higher the filter, the crispier the sound of the cymbal. Then, a similar envelope as before can be added to control the precision of the cymbal. A short envelope would create a closed hi-hat sound, while a longer envelope would generate an open hi-hat/normal cymbal sound."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c2cc8c5-b6af-44bf-9d59-4540d7d22085",
   "metadata": {},
   "outputs": [],
   "source": [
    "length = int(fs/6)\n",
    "\n",
    "noise = 2*np.random.random(length) - 1\n",
    "noise = butter_pass_filter(noise, np.array([8000]), fs, \"high\", order=3)\n",
    "\n",
    "envelope = np.ones(length) \n",
    "envelope[:10] = np.linspace(0,1,10)\n",
    "envelope[10:] = np.logspace(0, -2, envelope.size-10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96dd4108-b1e6-45ce-ba7a-11ae96f239a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "hihat = normalize(envelope * noise)\n",
    "\n",
    "plt.figure(figsize=figsize)\n",
    "plt.plot(hihat)\n",
    "plt.xlabel(\"Time [samples]\")\n",
    "plt.ylabel(\"Amplitude\")\n",
    "#plt.savefig(\"hihat.pdf\", dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Plot\n",
    "f, t, Zxx = signal.stft(hihat, fs, nperseg=400)\n",
    "plt.figure(figsize=figsize)\n",
    "plt.pcolormesh(t, f, np.abs(Zxx), cmap='nipy_spectral', shading='gouraud')\n",
    "plt.ylabel('Frequency [Hz]')\n",
    "plt.xlabel('Time [sec]')\n",
    "plt.ylim(20, 22500)\n",
    "plt.yscale(\"log\")\n",
    "#plt.savefig(\"hihat_stft.pdf\", dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "Audio(hihat, rate=fs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "224f99b0-80fe-440f-9350-da898840d889",
   "metadata": {},
   "source": [
    "### 2.4. Creating a drum beat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69ab1ce3-35eb-49a6-a4c5-7578fe2fa279",
   "metadata": {},
   "source": [
    "Using these 3 drum \"samples\", we can now create our own drum beat! To this extent, let us first implement a function to generate audio sequences given a boolean array indicating on which beats to play a note or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ddd582d-587b-4bb1-9b1e-a46ac8733456",
   "metadata": {},
   "outputs": [],
   "source": [
    "def beat_maker(pattern, sample, bpm=160):\n",
    "    \"\"\"\n",
    "    1-track beat rhythm generator.\n",
    "    pattern: the 0/1 pattern of the track (0 is no beat, 1 is beat)\n",
    "    sample: the sample to use for the track\n",
    "    bpm: the bpm (speed) of the rhythm\n",
    "    return: an audio track of the played rhythm\n",
    "    \"\"\"\n",
    "    out = np.zeros( int(fs * pattern.size /(bpm/60)) )\n",
    "    for i in range(pattern.size):\n",
    "        if pattern[i]: \n",
    "            k = int( i * fs /(bpm/60) )\n",
    "            out[k:np.minimum(out.size, k+sample.size)] += sample[:np.minimum(sample.size, out.size-k)]\n",
    "            \n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe30d18b-c5cd-40b8-adaf-c0a5036c72f5",
   "metadata": {},
   "source": [
    "Using that function, we can now write a track for all 3 drum elements, and merge them together!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3110fb21-65a5-4797-8d7e-5cb2f5d74d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "bpm=1000\n",
    "\n",
    "hats   = beat_maker(np.array([1,0,0,0,1,1,1,1,1,0,0,0,1,0,0,0,1,0,1,0,1,0,1,0,1,1,1,1,1,0,1,0]), hihat, bpm)\n",
    "kicks  = beat_maker(np.array([1,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0]), kick,  bpm)\n",
    "snares = beat_maker(np.array([0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]), snare, bpm)\n",
    "\n",
    "beat = normalize(.7*hats + .3*kicks + snares)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faca040b-da60-4ea2-b841-6cc9c700832e",
   "metadata": {},
   "source": [
    "Pretty sick (or cringe...), right? Note how easy it is to create a *trap* beat by simply putting a lot of fast hats together. A possible improvement of our little rhythm creator would be to be able to control the pitch and amplitude of each sample independetly, allowing to create even more *trappy* beats. let's look at it in the frequency domain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83368546-44de-437c-a5f8-3090c6c5ff84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "f, t, Zxx = signal.stft(beat, fs, nperseg=400)\n",
    "plt.figure(figsize=figsize)\n",
    "plt.pcolormesh(t, f, np.abs(Zxx), cmap='nipy_spectral', shading='gouraud')\n",
    "plt.ylabel('Frequency [Hz]')\n",
    "plt.xlabel('Time [sec]')\n",
    "plt.ylim(100, 14000)\n",
    "plt.yscale(\"log\")\n",
    "plt.show()\n",
    "\n",
    "Audio(beat, rate=fs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84261775-9900-4c43-8611-17051a092b60",
   "metadata": {},
   "source": [
    "## 3. Wind instruments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d34472f2-f11f-4f1b-84df-807b7a9a0abe",
   "metadata": {},
   "source": [
    "Finally, let us try to modelize a simple wind instrument, like a trumpet. Wind intruments have the particularity that as long as the musician blows in it, it keeps playing at a constant volume. However, a normal person generally does not perfectly blows an even amount of air over time. This results in light variations in the pitch of the instrument over time, quite typical of wind instruments.\n",
    "\n",
    "Amplitude-wise, the musician has to start blowing air as precisely as possible in the trumpet to start making a sound. There again, as precise as one can be, it will still be less precise than plucking a string, hence wind intruments typically have a longer attack and release than other instruments.\n",
    "\n",
    "<img src=\"https://images-na.ssl-images-amazon.com/images/I/712ZyImPK8L._AC_SL1500_.jpg\" alt=\"Drawing\" style=\"width: 40%;\"/>\n",
    "\n",
    "Let us now start to implement it! The first thing we need is a bright, clear synthetic sound. The saw wave we implemented in the synthesizer notebook would be a good fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77d458ab-d0d5-4e6e-ac6e-89827c73a7a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def saw(A, w, phi, n):\n",
    "    return 2*A/np.pi * np.arctan( np.tan( w*n/2 - phi))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cdc5054-f7a1-422f-ae74-14482906e7e7",
   "metadata": {},
   "source": [
    "Before moving the generating an actual sound, let us think of what we need. Above, we discussed that the pressure in the intrument is not constant while playing. Actually, when we start playing the trumpet, the air pressure quickly increases, but still in an audible way. This results in a quick raise in pitch as we start playing. It is also popular to add another pitch change from above this time, creating more \"breath\" in the initial sound attack. This can be modelled by a pitch envelope going from below, and one from above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c7eef0b-c3c7-4433-a294-ed7261a6fc0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "length = fs\n",
    "\n",
    "# Pitch envelope 1\n",
    "detune1 = np.zeros(length) \n",
    "detune1[:20000] = -np.logspace(.7, -3 ,20000)\n",
    "\n",
    "# Pitch envelope 2\n",
    "detune2 = np.zeros(length) \n",
    "detune2[:20000] = np.logspace(.3, -3 ,20000)\n",
    "\n",
    "plt.figure(figsize=figsize)\n",
    "plt.plot(detune1)\n",
    "plt.plot(detune2)\n",
    "plt.xlabel(\"Time [samples]\")\n",
    "plt.ylabel(\"Envelope pitch [Hz]\")\n",
    "#plt.savefig(\"wind_pitch_envelope.pdf\", dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ad55483-7d15-4d3d-913d-959fa80f09ee",
   "metadata": {},
   "source": [
    "The second thing we discussed is that even when the desired pitch is reached, it is hard to keep an exactly constant pressure in the instrument, resulting is very small variations in the pitch over time. This can be simply tackled by LFOs. Let's implement one for each pitch envelope above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1828bc92-143a-449e-8d39-171f68b8811c",
   "metadata": {},
   "outputs": [],
   "source": [
    "lfo1 = sine(.1, .00041, 0, np.arange(length)) # Low freqency oscillator 1\n",
    "lfo2 = sine(.1, .00011, 0, np.arange(length)) # Low freqency oscillator 2\n",
    "\n",
    "plt.figure(figsize=figsize)\n",
    "plt.plot(lfo1)\n",
    "plt.plot(lfo2)\n",
    "plt.xlabel(\"Time [samples]\")\n",
    "plt.ylabel(\"LFOs pitch [Hz]\")\n",
    "#plt.savefig(\"kick_env.pdf\", dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3023bc41-42ef-4fee-a142-ebbb753fff6d",
   "metadata": {},
   "source": [
    "Okay, we can now generate 2 saw sounds, with the pitch altered by both the LFOs and the pitch envelopes! We subsequently filter the sawteeth with a lowpass as trumpets do not generate that many frequencies about 2kHz!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b8c5cb-7eab-4d4e-a78b-96b73abe66f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_saw1 = saw(1, 300/fs*2*np.pi, detune1+lfo1, np.arange(length))\n",
    "my_saw1 = butter_pass_filter(my_saw1, np.array([2400]), fs, \"low\", order=3)\n",
    "\n",
    "my_saw2 = saw(1, 301/fs*2*np.pi, detune2+lfo2, np.arange(length))\n",
    "my_saw2 = butter_pass_filter(my_saw2, np.array([2400]), fs, \"low\", order=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff40beb1-0021-40d9-ae5b-6ffab33efd09",
   "metadata": {},
   "source": [
    "Let us listen to both sawteeth together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d4b262-bca6-44c3-83a8-a95f5d588009",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_saw = normalize(0.7*my_saw1+0.3*my_saw2)\n",
    "\n",
    "Audio(my_saw, rate=fs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "065048f1-5f9e-4213-a825-cc5bfed2d5f7",
   "metadata": {},
   "source": [
    "Sounds already not too bad, does it? A bit harsh maybe, this is because we still haven't implement the amplitude envelope. As we said, the attack is rather slow, then the sustain is constant as the player keeps blowing in the trumpet, and finally the release is quite slow too! Let us do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d0bbbab-48a5-40f6-b05f-838d36199621",
   "metadata": {},
   "outputs": [],
   "source": [
    "attack = 5000\n",
    "release = 20000\n",
    "\n",
    "envelope = np.ones(length) \n",
    "envelope[:attack] = 1 - np.logspace(0, -2 ,attack)\n",
    "envelope[attack:] = 0.7 + 0.3*np.logspace(0, -10 ,length-attack)\n",
    "envelope[-release:] = 0.7*np.logspace(0, -2, release)\n",
    "\n",
    "\n",
    "plt.figure(figsize=figsize)\n",
    "plt.plot(envelope)\n",
    "plt.xlabel(\"Time [samples]\")\n",
    "plt.ylabel(\"Envelope amplitude\")\n",
    "#plt.savefig(\"wind_env.pdf\", dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc961a9d-44d3-48e9-b679-5c85eda67470",
   "metadata": {},
   "source": [
    "Cool, let us finally put all this together and listen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "718f3d75-4847-4a7e-bd26-3e66c4ec0c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "wind = envelope * my_saw\n",
    "\n",
    "# Plot\n",
    "f, t, Zxx = signal.stft(wind, fs, nperseg=400)\n",
    "plt.figure(figsize=figsize)\n",
    "plt.pcolormesh(t, f, np.abs(Zxx), cmap='nipy_spectral', shading='gouraud')\n",
    "plt.ylabel('Frequency [Hz]')\n",
    "plt.xlabel('Time [sec]')\n",
    "plt.ylim(100, 14000)\n",
    "plt.yscale(\"log\")\n",
    "plt.show()\n",
    "\n",
    "Audio(wind, rate=fs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a74b97ad-afbb-4600-9ba7-c733d203e0a3",
   "metadata": {},
   "source": [
    "### 3.1. Play a song!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1563babb-aa5e-46b2-8c00-620477e2fd4c",
   "metadata": {},
   "source": [
    "Let us try to play a melody with it, like for the guitar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b916d91-34fd-4bff-b5e6-d9a7328542da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trumpet(w,N):\n",
    "\n",
    "    # Pitch envelope 1\n",
    "    detune1 = np.zeros(N) \n",
    "    detune1[:3000] = -np.logspace(.7, -3 ,3000)\n",
    "\n",
    "    # Pitch envelope 2\n",
    "    detune2 = np.zeros(N) \n",
    "    detune2[:3000] = np.logspace(.3, -3 ,3000)\n",
    "\n",
    "    lfo1 = sine(.1, .00071, 0, np.arange(N)) # Low freqency oscillator 1\n",
    "    lfo2 = sine(.1, .00031, 0, np.arange(N)) # Low freqency oscillator 2\n",
    "    \n",
    "    my_saw1 = saw(1, w, detune1+lfo1, np.arange(N))\n",
    "    my_saw1 = butter_pass_filter(my_saw1, np.array([2400]), fs, \"low\", order=3)\n",
    "\n",
    "    my_saw2 = saw(1, w*1.001, detune2+lfo2, np.arange(N))\n",
    "    my_saw2 = butter_pass_filter(my_saw2, np.array([2400]), fs, \"low\", order=3)\n",
    "\n",
    "    my_saw = normalize(my_saw1+my_saw2)\n",
    "    \n",
    "    attack = 1500\n",
    "    release = 2000\n",
    "\n",
    "    envelope = np.ones(N) \n",
    "    envelope[:attack] = 1 - np.logspace(0, -2 ,attack)\n",
    "    envelope[attack:] = 0.7 + 0.3*np.logspace(0, -10 , N-attack)\n",
    "    envelope[-release:] = 0.7*np.logspace(0, -2, release)\n",
    "\n",
    "    return my_saw * envelope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c71a787-adac-4b69-b0d4-ddefb74bc41c",
   "metadata": {},
   "outputs": [],
   "source": [
    "jingle = play_notes(tune, time_scale=0.04, rate=2*fs, wave_engine=trumpet)\n",
    "Audio(jingle, rate=fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100582eb-04f4-4277-bbd5-04dd8faa12c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
